{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converter CSV para SQL\n",
    "Esse notebook lê os arquivos CSV e escreve um arquivo SQL que insere os dados no banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ler arquivos e juntar\n",
    "\n",
    "Vamos ler os 4 arquivos em CSV, juntar todos em um único dataframe e remover a coluna 'show_id', pois o id no nosso banco não será o mesmo id do arquivo original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le os 4 arquivos\n",
    "amazon = pd.read_csv('amazon_prime_titles.csv')\n",
    "disney = pd.read_csv('disney_plus_titles.csv')\n",
    "hulu = pd.read_csv('hulu_titles.csv')\n",
    "netflix = pd.read_csv('netflix_titles.csv')\n",
    "\n",
    "# Adiciona one-hot de plataforma\n",
    "amazon['amazon'] = True\n",
    "disney['disney'] = True\n",
    "netflix['netflix'] = True\n",
    "hulu['hulu'] = True\n",
    "\n",
    "# Adiciona data de inclusao para cada plataforma\n",
    "amazon.rename(columns={'date_added': 'date_added_amazon'}, inplace=True)\n",
    "disney.rename(columns={'date_added': 'date_added_disney'}, inplace=True)\n",
    "hulu.rename(columns={'date_added': 'date_added_hulu'}, inplace=True)\n",
    "netflix.rename(columns={'date_added': 'date_added_netflix'}, inplace=True)\n",
    "\n",
    "# Junta em um dataframe so\n",
    "shows = amazon.append(disney.append(hulu.append(netflix, ignore_index=True), ignore_index=True), ignore_index=True)\n",
    "\n",
    "# Zera as outras plataformas\n",
    "shows[['amazon','disney','hulu','netflix']] = shows[['amazon','disney','hulu','netflix']].fillna(False)\n",
    "\n",
    "# Remove a coluna 'show_id'\n",
    "shows.drop(columns=['show_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'title', 'director', 'cast', 'country', 'date_added_amazon',\n",
       "       'release_year', 'rating', 'duration', 'listed_in', 'description',\n",
       "       'amazon', 'date_added_disney', 'disney', 'date_added_hulu', 'hulu',\n",
       "       'date_added_netflix', 'netflix'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shows.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type                  22998\n",
       "title                 22998\n",
       "director              14736\n",
       "cast                  17677\n",
       "country               11499\n",
       "date_added_amazon       155\n",
       "release_year          22998\n",
       "rating                22134\n",
       "duration              22516\n",
       "listed_in             22998\n",
       "description           22994\n",
       "amazon                22998\n",
       "date_added_disney      1447\n",
       "disney                22998\n",
       "date_added_hulu        3045\n",
       "hulu                  22998\n",
       "date_added_netflix     8797\n",
       "netflix               22998\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shows.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Limpeza de dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSet(series):\n",
    "    seriesSet = set()\n",
    "    for seriesString in seriesSet.dropna().unique():\n",
    "        for element in seriesString.split(', '):\n",
    "            seriesSet.add(element)\n",
    "    return seriesSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conserta a duração de alguns shows que estão na coluna rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "shows.loc[shows['rating'].str.contains(r\"min|Season\") == True,['duration']] = shows[shows['rating'].str.contains(r\"min|Season\") == True]['rating']\n",
    "shows.loc[shows['rating'].str.contains(r\"min|Season\") == True,['rating']] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Junta os shows duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicatedShows = [v for v in shows.groupby(['title','type','release_year']).groups.values() if len(v)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00%\r"
     ]
    }
   ],
   "source": [
    "def mergeRow(series):\n",
    "    return ', '.join([e for e in createSet(series)])\n",
    "\n",
    "def dateAdded(dates):\n",
    "    return np.NaN if dates.isnull().all() else dates.dropna().iloc[0]\n",
    "\n",
    "mergedShows = {\n",
    "    'type': [],\n",
    "    'title': [],\n",
    "    'release_year': [],\n",
    "    'director': [],\n",
    "    'cast': [],\n",
    "    'country': [],\n",
    "    'listed_in': [],\n",
    "    'amazon': [],\n",
    "    'disney': [],\n",
    "    'hulu': [],\n",
    "    'netflix': [],\n",
    "    'date_added_amazon': [],\n",
    "    'date_added_disney': [],\n",
    "    'date_added_hulu': [],\n",
    "    'date_added_netflix': [],\n",
    "    'duration': [],\n",
    "    'rating': [],\n",
    "    'description': []\n",
    "}\n",
    "duplicatedIds = []\n",
    "\n",
    "i = 0\n",
    "n = len(duplicatedShows)\n",
    "\n",
    "for showsId in duplicatedShows:\n",
    "    duplicatedIds.extend(showsId)\n",
    "    duplicatedPair = shows.loc[showsId]\n",
    "    \n",
    "    mergedShows['type'].append(duplicatedPair['type'].iloc[0])\n",
    "    mergedShows['title'].append(duplicatedPair['title'].iloc[0])\n",
    "    mergedShows['release_year'].append(duplicatedPair['release_year'].iloc[0])\n",
    "\n",
    "    mergedShows['director'].append(mergeRow(duplicatedPair['director']))\n",
    "    mergedShows['cast'].append(mergeRow(duplicatedPair['cast']))\n",
    "    mergedShows['country'].append(mergeRow(duplicatedPair['country']))\n",
    "    mergedShows['listed_in'].append(mergeRow(duplicatedPair['listed_in']))\n",
    "\n",
    "    mergedShows['amazon'].append(duplicatedPair['amazon'].any())\n",
    "    mergedShows['disney'].append(duplicatedPair['disney'].any())\n",
    "    mergedShows['hulu'].append(duplicatedPair['hulu'].any())\n",
    "    mergedShows['netflix'].append(duplicatedPair['netflix'].any())\n",
    "\n",
    "    mergedShows['date_added_amazon'].append(dateAdded(duplicatedPair['date_added_amazon']))\n",
    "    mergedShows['date_added_disney'].append(dateAdded(duplicatedPair['date_added_disney']))\n",
    "    mergedShows['date_added_hulu'].append(dateAdded(duplicatedPair['date_added_hulu']))\n",
    "    mergedShows['date_added_netflix'].append(dateAdded(duplicatedPair['date_added_netflix']))\n",
    "\n",
    "    mergedShows['duration'].append(duplicatedPair.mode()['duration'].iloc[0])\n",
    "    mergedShows['rating'].append(duplicatedPair.mode()['rating'].iloc[0])\n",
    "    mergedShows['description'].append(duplicatedPair.mode()['description'].iloc[0])\n",
    "    \n",
    "    i += 1\n",
    "    print('{:03.2f}%\\r'.format(100*i/n),end='')\n",
    "    \n",
    "shows = shows.drop(duplicatedIds)\n",
    "shows = shows.append(pd.DataFrame.from_dict(mergedShows), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = createSet(shows['country'])\n",
    "genre = createSet(shows['listed_in'])\n",
    "actors = createSet(shows['cast'])\n",
    "directors = createSet(shows['director'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ?. Coletar as imagens dos artistas\n",
    "Para isso será feita uma raspagem do site 'biography.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "actorName = 'Nicolas Cage'\n",
    "actorNameFormatted = actorName.lower().replace(' ', '-')\n",
    "actorUrl = f'https://www.biography.com/actor/{actorNameFormatted}'\n",
    "\n",
    "try:\n",
    "  with requests.get(actorUrl) as actorReq:\n",
    "    imgUrl = re.findall('<img src=\"[^\"]*\"', actorReq.text)[2][10:-1]\n",
    "    with requests.get(imgUrl, stream=True) as imgReq:\n",
    "      with open(f'{actorNameFormatted}.png','wb') as file:\n",
    "        shutil.copyfileobj(imgReq.raw, file)\n",
    "except:\n",
    "  print(f'{actorName} not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dump.sql','w') as f:\n",
    "    f.write(\"insert into Plataforma(nome) values ('Amazon Prime'), ('Netflix'), ('Disney+'), ('Hulu')\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
